<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[BlueChipTek]]></title>
  <link href="http://bluechiptek.github.io/atom.xml" rel="self"/>
  <link href="http://bluechiptek.github.io/"/>
  <updated>2013-11-04T15:42:03-08:00</updated>
  <id>http://bluechiptek.github.io/</id>
  <author>
    <name><![CDATA[Kord Campbell]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Installing OpenStack Cinder in 10 Minutes]]></title>
    <link href="http://bluechiptek.github.io/blog/2013/11/04/openstack-cinder/"/>
    <updated>2013-11-04T11:38:00-08:00</updated>
    <id>http://bluechiptek.github.io/blog/2013/11/04/openstack-cinder</id>
    <content type="html"><![CDATA[<p>The <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;ved=0CC4QFjAA&amp;url=http%3A%2F%2Fwiki.openstack.org%2FCinder&amp;ei=4IonUufGCIPuiQKS2oDICA&amp;usg=AFQjCNEMptnoNy9ZGAR6Qbuy9KhaMfvZzQ&amp;sig2=6LIC8BxMqWAbsycyyUNL3A&amp;bvm=bv.51773540,d.cGE">Cinder project</a> provides volume storage management for OpenStack deployments.  Cinder volumes appear as block storage devices to instances started in an OpenStack environment.  Cinder is also used by OpenStack for storage of instance snapshots and can be used to boot cloned images of existing running instances.</p>

<p>You can familiarize yourself with the Cinder install process by watching the video below.</p>

<p><a href="http://vimeo.com/73001135"><img src="https://raw.github.com/rackerlabs/vagrantstack/master/openstack_movie.png" alt="ScreenShot" /></a></p>

<p>Before we drop into the guide, I&rsquo;d like to thank <a href="http://bluechiptek.com">Blue Chip Tek</a> for providing hardware, advice and setup assistance, <a href="http://dell.com/">Dell Computers</a> for donating the test hardware, and the awesome folks at <a href="http://rackspace.com/">Rackspace</a> for writing and supporting the <a href="https://github.com/rcbops/chef-cookbooks">Chef scripts</a> which are used for the bulk of the setup process.</p>

<h3>Prerequisites for Install</h3>

<p>Before installing Cinder, you should ensure you&rsquo;ve installed your OpenStack cluster using the <a href="https://github.com/bluechiptek/bluechipstack/blob/master/README.md">Installing OpenStack in 10 Minutes</a> guide.  The primary requirement is you have a local instance of the Vagrant Chef server running which will be used in this guide to deploy Cinder to your nodes.</p>

<p>Cinder does storage management, so you&rsquo;ll also need a storage device configured to store data.  Typically this is done with hard drives or SSDs.  This guide currently uses the method of creating a 1TB loopback device attached to a file stored in the root partition on each node in your cluster.  If your root partition doesn&rsquo;t have 1TB of storage available on it, you can either shrink the number to accomidate or install and provision a physical volume on another storage device.</p>

<p><em>Note: This guide will be updated to include instructions for using a physical volume as the storage device in a later revision.</em></p>

<h3>Build the Loopback File and Persist It</h3>

<p>Start by checking on the amount of storage you have available on your node.  This guide assume the loopback file will be created in the root partition.  Become root and then execute the following command:</p>

<pre><code>df -ah /
</code></pre>

<p>Take a gander at the result:</p>

<pre><code>root@flop:/home/kord# df -ah /
Filesystem      Size  Used Avail Use% Mounted on
/dev/sda2       2.8T  2.5G  2.6T   1% /
</code></pre>

<p>We&rsquo;re good to create a 1TB file on that partition.  Now execute the command to create the file we&rsquo;ll loop:</p>

<pre><code>dd if=/dev/zero of=cinder-volumes bs=1 count=0 seek=1024G
</code></pre>

<p>Results come back instantly:</p>

<pre><code>root@flop:/home/kord# dd if=/dev/zero of=/cinder-volumes bs=1 count=0 seek=1024G
0+0 records in
0+0 records out
0 bytes (0 B) copied, 1.035e-05 s, 0.0 kB/s
</code></pre>

<p>Now loop up the file to the loopback device (we&rsquo;ll use loop2 here):</p>

<pre><code>losetup /dev/loop2 /cinder-volumes
</code></pre>

<p>Finally, create a rc file to mount the loopback file after a reboot:</p>

<pre><code>echo "losetup /dev/loop2 /cinder-volumes; exit 0;" &gt; /etc/init.d/cinder-setup-backing-file
chmod 755 /etc/init.d/cinder-setup-backing-file
ln -s /etc/init.d/cinder-setup-backing-file /etc/rc2.d/S10cinder-setup-backing-file
</code></pre>

<h3>Physical &amp; Volume Group Creation</h3>

<p>The next step is to initialize a LVM volume named <em>cinder-volumes</em>.  That name is used by default for all Cinder installs.  It can be changed in the configuration files in <strong>/etc/cinder/</strong> after you install it, but we&rsquo;ll assume here we&rsquo;re leaving it as the default.   Run the commands in one cut and paste frenzy:</p>

<pre><code>sudo pvcreate /dev/loop2
sudo vgcreate cinder-volumes /dev/loop2
</code></pre>

<p>Revel in the vast awesomeness of your successful paste job:</p>

<pre><code>root@flop:/home/kord# sudo pvcreate /dev/loop2
Physical volume "/dev/loop2" successfully created
root@flop:/home/kord# sudo vgcreate cinder-volumes /dev/loop2
Volume group "cinder-volumes" successfully created
</code></pre>

<p>Double check your work with <strong>pvdisplay</strong> and <strong>vgdisplay</strong>:</p>

<pre><code>root@flop:/home/kord# pvdisplay; vgdisplay
  --- Physical volume ---
  PV Name               /dev/loop2
  VG Name               cinder-volumes
  PV Size               1.00 TiB / not usable 4.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              262143
  Free PE               262143
  Allocated PE          0
  PV UUID               XnvA5r-wBw0-WIhd-9FHd-n4lT-71em-uYCLJt

        --- Volume group ---
  VG Name               cinder-volumes
  System ID
  Format                lvm2
  Metadata Areas        1
  Metadata Sequence No  1
  VG Access             read/write
  VG Status             resizable
  MAX LV                0
  Cur LV                0
  Open LV               0
  Max PV                0
  Cur PV                1
  Act PV                1
  VG Size               1024.00 GiB
  PE Size               4.00 MiB
  Total PE              262143
  Alloc PE / Size       0 / 0
  Free  PE / Size       262143 / 1024.00 GiB
  VG UUID               vabQ1q-mxZ2-ofrn-6640-rriR-jln1-WHm4jm
</code></pre>

<h3>Install Cinder via Vagrant Chef</h3>

<p>Move on over to the computer that was used to provision the nodes in your install.  If you&rsquo;ve halted the Vagrant server, restart it first and then ssh into it and become root:</p>

<pre><code>Beast:texasholdem kord$ cd bluechipstack/
Beast:bluechipstack kord$ vagrant up
Bringing machine 'default' up with 'virtualbox' provider...
...
[default] -- /vagrant
Beast:bluechipstack kord$ vagrant ssh
Welcome to Ubuntu 12.04 LTS (GNU/Linux 3.2.0-23-generic x86_64)
...
Welcome to your Vagrant-built virtual machine.
Last login: Wed Sep  4 18:54:12 2013 from 10.0.2.2
vagrant@chef-server:~$ sudo su
root@chef-server:/home/vagrant#
</code></pre>

<p>Now test Chef is still aware of the servers:</p>

<pre><code>knife node list
</code></pre>

<p>Time to install Cinder on the nodes.  Type the following to add the Cinder storage role to the nodes (making sure to change the node name(s) in the process):</p>

<pre><code>knife node run_list add flop 'role[cinder-volume]'
knife node run_list add turn 'role[cinder-volume]'
</code></pre>

<h3>Volume Clear</h3>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Installing OpenStack Grizzly in 10 Minutes]]></title>
    <link href="http://bluechiptek.github.io/blog/2013/08/30/openstack-install/"/>
    <updated>2013-08-30T14:45:00-07:00</updated>
    <id>http://bluechiptek.github.io/blog/2013/08/30/openstack-install</id>
    <content type="html"><![CDATA[<p>The <a href="http://www.openstack.org/software/">OpenStack</a> project provides a way to turn bare metal servers into a private cloud. It&rsquo;s been over a year since I published the first <a href="http://www.stackgeek.com/guides/gettingstarted.html">Install OpenStack in 10 Minutes</a> guide and now, nearly 10K installs later, I&rsquo;m pleased to announce the quickest and easiest way yet to get an OpenStack cluster running.</p>

<p>Before we drop into the guide, I&rsquo;d like to thank <a href="http://bluechiptek.com">Blue Chip Tek</a> for providing hardware, advice and setup assistance, <a href="http://dell.com/">Dell Computers</a> for donating the test hardware, and the awesome folks at <a href="http://rackspace.com/">Rackspace</a> for writing and supporting the <a href="https://github.com/rcbops/chef-cookbooks">Chef scripts</a> which are used for the bulk of the setup process.</p>

<p>The scripts provided in this guide build a Chef server inside a <a href="http://vagrantup.com/">Vagrant box</a>, which ends up acting as a sort of &lsquo;raygun&rsquo; to blast OpenStack onto the nodes.  Everyone knows <a href="https://www.google.com/search?q=raygun&amp;safe=off">rayguns</a> are awesome.</p>

<h3>Prerequisites for Install</h3>

<p>The new install scripts are <a href="https://github.com/bluechiptek/bluechipstack">available for download</a> from BlueChip&rsquo;s Github account.  It is recommended you familiarize yourself first with the install process by watching the screencast below.</p>

<p><a href="http://vimeo.com/73001135"><img src="https://raw.github.com/bluechiptek/bluechipstack/master/openstack_movie.png" alt="ScreenShot" /></a></p>

<p>Before you start, make sure you have a minimum of one bare metal node running <a href="http://www.ubuntu.com/download/server">Ubuntu Server 12.04</a>.  If you are installing on more than one node, make sure all the nodes are on the <a href="http://en.wikipedia.org/wiki/Private_network">same private IP block</a> and are able to talk to each other before proceeding.  All nodes will need Internet access via NAT provided by a DHCP server/router.</p>

<p>If you don&rsquo;t have Vagrant installed on your computer (desktop/laptop) yet, you&rsquo;ll need to download both <a href="http://vagrantup.com/">Vagrant</a> and <a href="https://www.virtualbox.org/">VirtualBox</a>:</p>

<ul>
<li><p>Install VirtualBox 4.2.16 for <a href="http://download.virtualbox.org/virtualbox/4.2.16/VirtualBox-4.2.16-86992-Win.exe">Windows</a> or <a href="http://download.virtualbox.org/virtualbox/4.2.16/VirtualBox-4.2.16-86992-OSX.dmg">OSX</a></p></li>
<li><p>Install Vagrant 1.2.7 for <a href="http://files.vagrantup.com/packages/7ec0ee1d00a916f80b109a298bab08e391945243/Vagrant_1.2.7.msi">Windows</a> or <a href="http://files.vagrantup.com/packages/7ec0ee1d00a916f80b109a298bab08e391945243/Vagrant-1.2.7.dmg">OSX</a>.</p></li>
</ul>


<p>Double click each package to run through the installation on your local machine.</p>

<h3>Download the Install Scripts</h3>

<p>Start a terminal on your local machine and make sure you have <em>git</em> installed.  If you don&rsquo;t, you can <a href="http://git-scm.com/downloads">download it here</a>.  Make and move yourself into a directory called <em>openstack</em>:</p>

<pre><code>mkdir openstack; cd openstack
</code></pre>

<p>Next, clone the scripts from the repo:</p>

<pre><code>git clone https://github.com/bluechiptek/bluechipstack.git
</code></pre>

<p>Now move into the scripts directory and take a gander at the scripts:</p>

<pre><code>cd bluechipstack; ls
</code></pre>

<h3>Create the Setup File</h3>

<p>The setup script provided in the repository will prompt you for a few variables, including the number of nodes for the cluster, the node IPs and names, and the network you&rsquo;ll be using for instances.  Start the setup script by typing the following:</p>

<pre><code>./openstack_setup.sh
</code></pre>

<p>Once the setup script finishes, you will have a <em>setuprc</em> file that will look something like this:</p>

<pre><code>export NUMBER_NODES=3
export NODE_1_HOSTNAME=nero
export NODE_1_IP=10.0.1.73
export NODE_2_HOSTNAME=spartacus
export NODE_2_IP=10.0.1.93
export NODE_3_HOSTNAME=invictus
export NODE_3_IP=10.0.1.94
export ROOT_PASSWD=af5b015ab50472e2368cdef95dfda120
export PUBLIC_NETWORK=10.0.1.0
export PRIVATE_NETWORK=10.0.55.0
export BRIDGE_INTERFACE=eth0
</code></pre>

<p>Before you continue with the install, double check the network interface names on your nodes:</p>

<pre><code>kord@nero:~$ ifconfig -a |grep Ethernet
br100     Link encap:Ethernet  HWaddr d4:3d:7e:33:f7:31  
eth0      Link encap:Ethernet  HWaddr d4:3d:7e:33:f7:31  
</code></pre>

<p>If your primary interface name is different than <strong>eth0</strong>, be sure to edit the <em>setuprc</em> file and change the <strong>BRIDGE_INTERFACE</strong> value to the correctly named interface.  Things will go horribly wrong later if you don&rsquo;t do this now!</p>

<p><em>Note: If you are using a Windows box, and <a href="http://www.cygwin.com/">can&rsquo;t run bash scripts</a>, you can move the</em>  <strong>setuprc.example</strong> <em>file  to</em>  <strong>setuprc</strong> <em>and edit as needed:</em></p>

<pre><code>move setuprc.example setuprc
notepad setuprc
dos2unix setuprc
</code></pre>

<h3>Provision the Chef Server</h3>

<p>The Chef server is built and started by the Vagrant manager and should take 5-10 minutes to build on a fast box and connection.  Start the server by typing:</p>

<pre><code>vagrant up
</code></pre>

<p><em>Note: If you have multiple network interfaces on your desktop or laptop, you will be prompted to choose one for the bridge that is created for the Vagrant server.</em></p>

<p>Once the Chef server is provisioned, ssh into it:</p>

<pre><code>vagrant ssh
</code></pre>

<p>Once you are logged into the server, become root and change into the <em>bluechipstack</em> directory:</p>

<pre><code>sudo su
cd /root/bluechipstack
</code></pre>

<p>Now run the install script to print out the node configuration commands:</p>

<pre><code>./openstack_install.sh
</code></pre>

<h3>Configuring the Nodes</h3>

<p>You will need to do some manual configuration of your nodes now.  The install script you just ran will dump out instructions and commands you can use to cut and paste and save time.</p>

<p><strong>1. Begin by setting a temporary root password on each node:</strong></p>

<pre><code>root@chef-server# ssh user@hostname
user@hostname$ sudo passwd root 
[sudo] password for user: 
Enter new UNIX password: 
Retype new UNIX password: 
passwd: password updated successfully
user@hostname$ exit
...
</code></pre>

<p>You will need to replace the <strong>user</strong> and <strong>hostname</strong> appropriate for your nodes and repeat these steps for each and every node you specified in the setup.  For each node, you will be prompted for your user password twice and the new root password twice.</p>

<p><em>Note: The scripts will take care of disabling the temporary root password after the keys are installed.</em></p>

<p><strong>2. Next, push the root key to each node from the Chef server:</strong></p>

<pre><code>ssh-copy-id root@hostname
... 
</code></pre>

<p>As above, you will need to replace <strong>hostname</strong> with the node&rsquo;s actual hostname and then repeat this for each and every node in your cluster.  You will be prompted by the nodes for the root password you set in step 1 above.</p>

<h3>Delopy the Nodes</h3>

<p>The deploy script installs the Chef client on all the nodes you specified in the <em>setuprc</em> file.  After the deploy script is done, manually running the chef-client command kicks off the install of OpenStack.  Start the install of the client by typing the following from the Chef server:</p>

<pre><code>./openstack_deploy.sh
</code></pre>

<p>Once the deployment script completes, ssh to each node and manually run the Chef client command:</p>

<pre><code>root@chef-server# ssh root@hostname
root@hostname# chef-client
...
</code></pre>

<p>As you did earlier, replace <strong>hostname</strong> here with the actual hostname of each node.  Repeat this for each and every node in your cluster.  <strong>You may run these commands simultaneously on all nodes to speed up the install process.</strong></p>

<p>The first node in your cluster will be configured as an all-in-one controller.  This node will host the database for OpenStack, provide authentication, host the web UI, and perform network coordination.  The all-in-one node will also serve as a nova-compute node.  If you have more than one node in your cluster, the remainder of the nodes will be deployed as nova-compute nodes.</p>

<h3>Starting Instances</h3>

<p>Once the all-in-one node is provisioned, you should be able to log into the web UI for OpenStack.  Enter the IP address of the all-in-one node, which should be the <strong>NODE_1_IP</strong> variable in your Chef server environment:</p>

<pre><code>http://10.0.1.73
</code></pre>

<p>The default user for the web UI is <strong>admin</strong> and the default password is <strong>secrete</strong>.</p>

<p>You can refer to the <a href="http://vimeo.com/41807514">video guide</a> for getting started using the UI.</p>

<h3>Tweaking Configuration</h3>

<p>If you have any specific configuration you need to perform on your boxes, for example changing the contents of the nova.conf, then that can be done by modifying the recipes which were downloaded to your machine during setup.</p>

<pre><code>cd /root/chef-cookbooks/cookbooks
</code></pre>

<p>The config options are normally set in the attributes/default.rb file located inside the specific cookbooks. For example, to configure specific options involving nova you would edit the nova cookbook attributes file located at:</p>

<pre><code>nano /root/chef-cookbooks/cookbooks/nova/attributes/default.rb
</code></pre>

<p>From there you can configure specific options, for example if your machines do not support hardware virtualization you would change the virt_type setting:</p>

<pre><code>default["nova"]["libvirt"]["virt_type"]
</code></pre>

<p>Once you are done making changes to the server attributes you must then apply these changes before they will push out to the nodes:</p>

<pre><code>knife cookbook upload *modified-cookbook-name-here* -o /root/chef-cookbooks/cookbooks
</code></pre>

<p>If you edited multiple cookbooks and don&rsquo;t feel like specifying them one-by-one, you can simply re-upload the whole directory:</p>

<pre><code>knife cookbook upload -a -o /root/chef-cookbooks/cookbooks
</code></pre>

<p>Once you have finished applying the changes you can either wait for the servers to phone home and download the changes, or you can run the chef client command on each box via ssh.</p>

<pre><code>chef-client --once
</code></pre>

<h3>Troubleshooting</h3>

<p>If anything goes wrong with the install, be sure to ask for help.  The easiest way to get help is to <a href="https://groups.google.com/forum/?fromgroups#!category-topic/stackgeek/openstack/_zbeGoOBg-Q">post in the forums</a>.  Here are a few simple suggestions you can try:</p>

<p><strong>1. Check you can ping your nodes by name from the Chef server:</strong></p>

<pre><code>root@chef-server# ping nero
64 bytes from nero (10.0.1.100): icmp_req=1 ttl=64 time=0.463 ms
^C
--- nero ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 0.463/0.463/0.463/0.000 ms
</code></pre>

<p><strong>2. Check you can ping your Chef server by name from a node:</strong></p>

<pre><code>root@chef-server# ssh nero 
root@nero# ping chef-server
PING chef-server (10.0.1.57) 56(84) bytes of data.
64 bytes from chef-server (10.0.1.57): icmp_req=1 ttl=64 time=0.455 ms
^C
--- chef-server ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 0.455/0.455/0.455/0.000 ms
</code></pre>

<p><strong>3. Check you can remotely execute commands on the nodes from the Chef server:</strong></p>

<pre><code>root@chef-server# ssh nero uptime
09:59:04 up 12 days, 15:04,  0 users,  load average: 0.10, 0.14, 0.14
</code></pre>

<p><strong>4. See what nodes Chef knows about:</strong></p>

<pre><code>root@chef-server# knife node list
invictus
nero
spartacus
</code></pre>

<p><strong>5. Run a sync on the environment for the nodes:</strong></p>

<pre><code>root@chef-server# knife exec -E 'nodes.transform("chef_environment:_default") { |n| n.chef_environment("grizzly") }'
</code></pre>

<p><strong>6. Rerun the chef-client on each node:</strong></p>

<pre><code>root@chef-server# ssh nero
root@nero# chef-client
</code></pre>

<p><strong>7. Check the OpenStack services are running normally:</strong></p>

<pre><code>root@nero:~# nova-manage service list
Binary           Host                       Zone             Status     State Updated_At
nova-scheduler   nero                       internal         enabled    :-)   2013-08-23 17:10:45
nova-conductor   nero                       internal         enabled    :-)   2013-08-23 17:10:49
nova-cert        nero                       internal         enabled    :-)   2013-08-23 17:10:48
nova-consoleauth nero                       internal         enabled    :-)   2013-08-23 17:10:48
nova-network     nero                       internal         enabled    :-)   2013-08-23 17:10:48
nova-compute     nero                       nova             enabled    :-)   2013-08-23 17:10:49
nova-network     invictus                   internal         enabled    :-)   2013-08-23 17:10:51
nova-compute     invictus                   nova             enabled    :-)   2013-08-23 17:10:47
nova-network     spartacus                  internal         enabled    :-)   2013-08-23 17:10:52
nova-compute     spartacus                  nova             enabled    :-)   2013-08-23 17:10:49
</code></pre>
]]></content>
  </entry>
  
</feed>
